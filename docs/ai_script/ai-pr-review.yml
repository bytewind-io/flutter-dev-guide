name: AI PR Review (batch review, resilient)

on:
  workflow_run:
    workflows: ["Dart Static Analysis"]
    types: [completed]

permissions:
  contents: read
  pull-requests: write
  checks: write
  issues: write

concurrency:
  group: ai-review-${{ github.event.workflow_run.id }}
  cancel-in-progress: true

jobs:
  ai_review:
    if: >
      github.event.workflow_run.event == 'pull_request' &&
      github.event.workflow_run.conclusion == 'success'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Standards (flutter-dev-guide)
        uses: actions/checkout@v4
        with:
          repository: bytewind-io/flutter-dev-guide
          path: standards
          ref: main

      # Новое: ставим парсеры YAML и маски путей для scope
      - name: Install rule parser deps
        run: npm install js-yaml@4 minimatch@9

      - name: AI review (batch inline + checks)
        uses: actions/github-script@v7
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          ENABLE_INLINE_REVIEW: "true"
          ENABLE_CHECKS: "true"
          DELETE_PREVIOUS: "true"
          STRICT_HEAD_SHA_MATCH: "true"
          COLLAPSE_SUGGESTION: "true"
          VERIFY_HEAD_SNIPPET: "true"
          OPENAI_MODEL_MAIN: gpt-4o
          OPENAI_MODEL_FALLBACK: gpt-4o-mini
          OPENAI_TARGET_TOKENS: "16000"
          OPENAI_MAX_OUTPUT_TOKENS: "1000"
          OPENAI_MAX_BATCHES: "6"
          OPENAI_INTER_BATCH_DELAY_MS: "1500"
          DIFF_READY_RETRIES: "6"
          DIFF_READY_DELAY_MS: "2500"
        with:
          github-token: ${{ github.token }}
          script: |
            const fs = require('fs');
            const path = require('path');

            // flags
            const ENABLE_INLINE = (process.env.ENABLE_INLINE_REVIEW || 'true') === 'true';
            const ENABLE_CHECKS = (process.env.ENABLE_CHECKS || 'true') === 'true';
            const DELETE_PREVIOUS = (process.env.DELETE_PREVIOUS || 'true') === 'true';
            const STRICT_SHA = (process.env.STRICT_HEAD_SHA_MATCH || 'true') === 'true';
            const COLLAPSE = (process.env.COLLAPSE_SUGGESTION || 'true') === 'true';
            const VERIFY_HEAD = (process.env.VERIFY_HEAD_SNIPPET || 'true') === 'true';

            // model/config
            const MODEL_MAIN = process.env.OPENAI_MODEL_MAIN || 'gpt-4o';
            const MODEL_FALLBACK = process.env.OPENAI_MODEL_FALLBACK || 'gpt-4o-mini';
            const TARGET_TOKENS = Number(process.env.OPENAI_TARGET_TOKENS || 16000);
            const MAX_OUTPUT_TOKENS = Number(process.env.OPENAI_MAX_OUTPUT_TOKENS || 1000);
            const MAX_BATCHES = Number(process.env.OPENAI_MAX_BATCHES || 6);
            const INTER_BATCH_DELAY_MS = Number(process.env.OPENAI_INTER_BATCH_DELAY_MS || 1500);
            const DIFF_READY_RETRIES = Number(process.env.DIFF_READY_RETRIES || 6);
            const DIFF_READY_DELAY_MS = Number(process.env.DIFF_READY_DELAY_MS || 2500);

            // helpers
            const TOKEN_CHAR_RATIO = 4;
            const CHAR_BUDGET = TARGET_TOKENS * TOKEN_CHAR_RATIO;
            const COMMENT_MARK = '<!-- ai-pr-review: flutter-dev-guide -->';
            const norm = s => (s || '').replace(/\r\n/g, '\n').replace(/[ \t]+$/gm, '').trim();
            const sleep = ms => new Promise(r => setTimeout(r, ms));
            const safeSlice = (str, max) => (!str || str.length <= max) ? (str || '') : str.slice(0, max);

            function isGeneratedFile(filename) {
              return (
                /\.g\.dart$/i.test(filename) || /\.freezed\.dart$/i.test(filename) ||
                /\.mocks?\.dart$/i.test(filename) || /\.gr\.dart$/i.test(filename) ||
                /\/gen\//i.test(filename) || /\/generated\//i.test(filename) || /\/build\//i.test(filename)
              );
            }

            function buildIndexesFromUnifiedPatch(patchText) {
              const lines = String(patchText || '').split('\n');
              const posMap = new Map(); // newLine -> patch position
              const codeMap = new Map(); // newLine -> added line code
              let newLine = 0;
              let position = 0;
              for (const line of lines) {
                position += 1;
                if (line.startsWith('@@ ')) {
                  const m = /^@@\s*-\d+(?:,\d+)?\s+\+(\d+)(?:,(\d+))?\s@@/.exec(line);
                  if (m) newLine = parseInt(m[1], 10);
                } else if (line.startsWith('+') && !line.startsWith('+++')) {
                  posMap.set(newLine, position);
                  codeMap.set(newLine, line.substring(1));
                  newLine += 1;
                } else if (line.startsWith(' ')) {
                  newLine += 1;
                }
              }
              return { posMap, codeMap };
            }

            function parseFullDiffByFile(fullDiff) {
              const blocks = {};
              const lines = String(fullDiff || '').split('\n');
              let curFile = null;
              let buf = [];
              function flush() { if (curFile && buf.length) blocks[curFile] = buf.join('\n'); buf = []; }
              for (const line of lines) {
                const m = /^diff --git a\/(.+?) b\/(.+)$/.exec(line);
                if (m) { flush(); curFile = m[2].replace(/^b\//, ''); continue; }
                if (curFile) buf.push(line);
              }
              flush();
              return blocks;
            }

            function pickAnchorLine(start, end, posMap) {
              for (let l = end; l >= start; l--) if (posMap.has(l)) return l;
              for (let l = start; l <= end; l++) if (posMap.has(l)) return l;
              for (let off = 1; off <= 3; off++) {
                if (posMap.has(end + off)) return end + off;
                if (posMap.has(start - off)) return start - off;
              }
              return null;
            }

            // --- PR context ---
            const pr = (context.payload.workflow_run?.pull_requests?.[0]?.number) || 0;
            if (!pr) { core.info('No PR number — nothing to do.'); return; }
            const { owner, repo } = context.repo;

            const runHeadSha = context.payload.workflow_run.head_sha;
            const prInfo = await github.rest.pulls.get({ owner, repo, pull_number: pr });
            const prHeadSha = prInfo.data?.head?.sha;
            const isFork = prInfo.data?.head?.repo?.id !== prInfo.data?.base?.repo?.id;

            if (STRICT_SHA && prHeadSha && runHeadSha && prHeadSha !== runHeadSha) {
              core.info(`Skip: workflow_run.head_sha (${runHeadSha}) != PR head.sha (${prHeadSha}).`);
              return;
            }

            const canInline = ENABLE_INLINE && !isFork;

            // --- delete previous outputs by this bot/mark ---
            if (DELETE_PREVIOUS) {
              try {
                const comments = await github.paginate(github.rest.issues.listComments, { owner, repo, issue_number: pr, per_page: 100 });
                for (const c of comments) {
                  const byBot = (c.user && (c.user.login === 'github-actions[bot]' || c.user.type === 'Bot'));
                  const hasMark = typeof c.body === 'string' && c.body.includes(COMMENT_MARK);
                  if (byBot && hasMark) await github.rest.issues.deleteComment({ owner, repo, comment_id: c.id }).catch(()=>{});
                }
              } catch(e) { core.warning('Delete old issue comments failed: ' + (e?.message || e)); }

              try {
                const reviewComments = await github.paginate(github.rest.pulls.listReviewComments, { owner, repo, pull_number: pr, per_page: 100 });
                for (const rc of reviewComments) {
                  const byBot = (rc.user && (rc.user.login === 'github-actions[bot]' || rc.user.type === 'Bot'));
                  const hasMark = typeof rc.body === 'string' && rc.body.includes(COMMENT_MARK);
                  if (byBot && hasMark) await github.rest.pulls.deleteReviewComment({ owner, repo, comment_id: rc.id }).catch(()=>{});
                }
              } catch(e) { core.warning('Delete old review comments failed: ' + (e?.message || e)); }
            }

            // --- wait for patches ready ---
            let files = [];
            let attempt = 0;
            while (attempt < DIFF_READY_RETRIES) {
              attempt++;
              files = await github.paginate(github.rest.pulls.listFiles, { owner, repo, pull_number: pr, per_page: 100 });
              if (files.length && files.some(f => f.patch)) break;
              await sleep(DIFF_READY_DELAY_MS);
            }

            const changed = files.filter(f =>
              ((/\.dart$/i.test(f.filename) || /pubspec\.(yaml|lock)$/i.test(f.filename)) && !isGeneratedFile(f.filename))
            );

            if (!changed.length) {
              await github.rest.issues.createComment({
                owner, repo, issue_number: pr,
                body: COMMENT_MARK + '\nНет релевантных изменений. Пропуск.'
              });
              return;
            }

            // indexes per file
            const indexesByFile = new Map();
            for (const f of changed) if (f.patch) indexesByFile.set(f.filename, buildIndexesFromUnifiedPatch(f.patch));

            // if some file has no patch, fetch full diff
            if (changed.some(f => !f.patch)) {
              try {
                const resp = await github.request('GET /repos/{owner}/{repo}/pulls/{pull_number}', {
                  owner, repo, pull_number: pr,
                  headers: { accept: 'application/vnd.github.v3.diff' }
                });
                const byFile = parseFullDiffByFile(String(resp.data || ''));
                for (const f of changed) {
                  if (!indexesByFile.has(f.filename) && byFile[f.filename]) {
                    indexesByFile.set(f.filename, buildIndexesFromUnifiedPatch(byFile[f.filename]));
                  }
                }
              } catch(e) { core.warning('Failed to fetch full PR diff: ' + (e?.message || e)); }
            }

            // annotated added-lines blocks for LLM
            const annotatedBlocks = [];
            for (const f of changed) {
              if (!f.patch) continue;
              const lines = String(f.patch).split('\n');
              const buf = ['### FILE: ' + f.filename];
              let newLine = 0;
              for (const line of lines) {
                if (line.startsWith('@@ ')) {
                  const m = /^@@\s*-\d+(?:,\d+)?\s+\+(\d+)(?:,(\d+))?\s@@/.exec(line);
                  if (m) newLine = parseInt(m[1], 10);
                  buf.push(line);
                } else if (line.startsWith('+') && !line.startsWith('+++')) {
                  buf.push('+' + newLine + '|' + line.substring(1));
                  newLine += 1;
                } else if (line.startsWith(' ')) {
                  newLine += 1;
                }
              }
              annotatedBlocks.push(buf.join('\n'));
            }

            // load rules context (MD + YAML)
            function walk(dir) { let out=[]; for (const e of fs.readdirSync(dir,{withFileTypes:true})) { const p=path.join(dir,e.name); if (e.isDirectory()) out=out.concat(walk(p)); else out.push(p);} return out; }
            let rulesCtx = '';
            const rulesRoot = path.join(process.cwd(), 'standards', 'docs', 'rules');
            if (fs.existsSync(rulesRoot)) {
              const mdFiles = walk(rulesRoot).filter(p => p.toLowerCase().endsWith('.md'));
              const MAXF = 10, MAXL = 100;
              for (const pth of mdFiles.slice(0, MAXF)) {
                try {
                  rulesCtx += '\n\n# FILE: ' + pth.replace(process.cwd() + path.sep, '') + '\n' +
                              fs.readFileSync(pth, 'utf8').split('\n').slice(0, MAXL).join('\n');
                } catch {}
              }
              rulesCtx = safeSlice(rulesCtx, Math.floor(CHAR_BUDGET * 0.3));
            }

            // YAML rules: parse + add compact JSON to context + prepare matchers
            const yaml = require(process.cwd() + '/node_modules/js-yaml');
            const { Minimatch } = require(process.cwd() + '/node_modules/minimatch');
            const YAML_RULES = new Map();
            const yamlFiles = fs.existsSync(rulesRoot) ? walk(rulesRoot).filter(p => /\.ya?ml$/i.test(p)) : [];
            for (const pth of yamlFiles) {
              try {
                const doc = yaml.load(fs.readFileSync(pth, 'utf8'));
                if (doc && doc.id) { doc.__path = pth; YAML_RULES.set(String(doc.id), doc); }
              } catch {}
            }
            if (YAML_RULES.size) {
              const pick = (r) => ({ id: r.id, message: r.message, ai_hint: r.ai_hint, scope: r.scope, detect: r.detect, allowlist_patterns: r.allowlist_patterns });
              for (const r of YAML_RULES.values()) {
                rulesCtx += '\n\n# RULE_YAML: ' + r.id + '\n' + safeSlice(JSON.stringify(pick(r), null, 2), 4000);
              }
            }

            // batching of annotated blocks
            const batches = []; let cur = '';
            for (const block of annotatedBlocks) {
              if ((cur + '\n' + block).length > Math.floor(CHAR_BUDGET * 0.6) && cur) {
                batches.push(cur); cur = block;
              } else {
                cur += (cur ? '\n' : '') + block;
              }
            }
            if (cur) batches.push(cur);
            if (batches.length > MAX_BATCHES) batches.length = MAX_BATCHES;

            // --- OpenAI call returning STRICT JSON ---
            async function callOpenAI_JSON(model, rules, annotatedDiff) {
              const system = 'You are a precise senior Flutter/Dart reviewer who returns STRICT JSON.';
              const user =
                'RULES и аннотированные добавленные строки DIFF ниже. Верни СТРОГО JSON формата:\n' +
                '{ "issues":[{"file":"lib/a.dart","start_line":123,"end_line":125,"rule_id":"ID","title":"Заголовок","explanation":"Коротко","problem_snippet":"<=20 строк","fix_suggestion":"замена (без ``` )"}]}\n' +
                'Номера строк — только из "+<line>|" аннотаций; максимум 8 issues; если нет — issues: [].\n\n' +
                `# RULES\n${rules}\n\n# DIFF (annotated added lines)\n${annotatedDiff}`;
              const payload = {
                model,
                temperature: 0.1,
                max_tokens: MAX_OUTPUT_TOKENS,
                messages: [{ role: 'system', content: system }, { role: 'user', content: user }]
              };
              let tries = 0;
              while (tries < 4) {
                tries++;
                try {
                  const res = await fetch('https://api.openai.com/v1/chat/completions', {
                    method: 'POST',
                    headers: { 'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`, 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                  });
                  const text = await res.text();
                  if (res.status === 429 || res.status === 400) {
                    if (payload.model !== MODEL_FALLBACK) {
                      payload.model = MODEL_FALLBACK; await sleep(2000 * tries); continue;
                    }
                    annotatedDiff = annotatedDiff.slice(0, Math.floor(annotatedDiff.length * 0.75));
                    payload.messages[1].content =
                      payload.messages[1].content.split('# DIFF (annotated added lines)\n')[0] +
                      '# DIFF (annotated added lines)\n' + annotatedDiff;
                    await sleep(2000 * tries); continue;
                  }
                  if (!res.ok) {
                    if (res.status >= 500) { await sleep(1500 * tries); continue; }
                    return { issues: [] };
                  }
                  let raw; try { raw = JSON.parse(text); } catch { raw = null; }
                  let content = raw?.choices?.[0]?.message?.content || text;
                  const fence = /```json\s*([\s\S]*?)```/i.exec(content);
                  if (fence) content = fence[1];
                  const first = content.indexOf('{'), last = content.lastIndexOf('}');
                  if (first >= 0 && last > first) content = content.slice(first, last + 1);
                  let data; try { data = JSON.parse(content); } catch { data = { issues: [] }; }
                  return data;
                } catch (e) { await sleep(1500 * tries); }
              }
              return { issues: [] };
            }

            if (!process.env.OPENAI_API_KEY) {
              await github.rest.issues.createComment({
                owner, repo, issue_number: pr,
                body: COMMENT_MARK + '\n⚠️ Не задан OPENAI_API_KEY.'
              });
              return;
            }

            // --- ask LLM for issues
            let allIssues = [];
            for (let i = 0; i < batches.length; i++) {
              const result = await callOpenAI_JSON(MODEL_MAIN, rulesCtx, batches[i]);
              if (Array.isArray(result.issues)) allIssues = allIssues.concat(result.issues);
              if (i < batches.length - 1 && INTER_BATCH_DELAY_MS > 0) await sleep(INTER_BATCH_DELAY_MS);
            }
            const seen = new Set();
            allIssues = allIssues.filter(it => {
              const key = `${it.file}|${it.start_line}|${it.end_line}|${it.title}`;
              if (seen.has(key)) return false; seen.add(key); return true;
            });

            // --- Deterministic post-filter using YAML rules (scope + detect + allowlist) ---
            function pathInScope(file, scope) {
              if (!scope) return true;
              const inc = Array.isArray(scope.include_paths) && scope.include_paths.length
                ? scope.include_paths.some(p => new Minimatch(p).match(file))
                : true;
              const exc = Array.isArray(scope.exclude_paths) && scope.exclude_paths.length
                ? scope.exclude_paths.some(p => new Minimatch(p).match(file))
                : false;
              return inc && !exc;
            }
            function compileRegex(str, flags) {
              try { return new RegExp(str, flags || 'gmu'); } catch { try { return new RegExp(str, 'gm'); } catch { return null; } }
            }
            function buildRuleMatcher(spec) {
              const pats = (spec?.detect?.patterns || []).map(p => compileRegex(p.regex, p.flags)).filter(Boolean);
              const allow = (spec?.allowlist_patterns || []).map(s => compileRegex(s, 'u')).filter(Boolean);
              // если нет паттернов — не блокируем вывод LLM (пропускаем)
              return (line) => {
                if (!pats.length) return true;
                if (allow.some(re => re.test(line))) return false;
                return pats.some(re => re.test(line));
              };
            }
            const matchers = new Map();
            for (const [id, spec] of YAML_RULES) matchers.set(id, { spec, match: buildRuleMatcher(spec) });

            allIssues = allIssues.filter(it => {
              const ruleId = String(it.rule_id || '').trim();
              const m = matchers.get(ruleId);
              if (!m) return true; // неизвестные правила не трогаем
              if (!pathInScope(it.file, m.spec.scope)) return false;
              const idx = indexesByFile.get(it.file); if (!idx) return false;
              const start = Number(it.start_line), end = Number(it.end_line);
              for (let l = start; l <= end; l++) {
                const line = idx.codeMap.get(l) || '';
                if (m.match(line)) return true;
              }
              return false;
            });

            // --- Build inline review comments (anchored by line/side) ---
            function pickAnchorLine2(start, end, posMap) {
              // prefer any added line inside the range, else near
              for (let l = end; l >= start; l--) if (posMap.has(l)) return l;
              for (let l = start; l <= end; l++) if (posMap.has(l)) return l;
              for (let off = 1; off <= 3; off++) {
                if (posMap.has(end + off)) return end + off;
                if (posMap.has(start - off)) return start - off;
              }
              return null;
            }

            const draftComments = [];
            for (const it of allIssues) {
              if (!it.file || !it.start_line || !it.end_line) continue;
              const idx = indexesByFile.get(it.file); if (!idx) continue;
              const anchor = pickAnchorLine2(Number(it.start_line), Number(it.end_line), idx.posMap);
              if (!anchor) continue;

              if (VERIFY_HEAD && idx.codeMap.has(anchor)) {
                try {
                  const res = await github.rest.repos.getContent({ owner, repo, path: it.file, ref: prHeadSha });
                  if (!Array.isArray(res.data) && res.data && res.data.content) {
                    const decoded = Buffer.from(res.data.content, 'base64').toString('utf8');
                    const lines = decoded.replace(/\r\n/g, '\n').split('\n');
                    const actual = lines[anchor - 1] ?? '';
                    if (norm(actual) !== norm(idx.codeMap.get(anchor))) continue;
                  }
                } catch {}
              }

              const fileUrl = `https://github.com/${owner}/${repo}/blob/${prHeadSha}/${it.file}#L${anchor}`;
              const vsUrl   = `https://vscode.dev/github/${owner}/${repo}/blob/${prHeadSha}/${it.file}?line=${anchor}`;
              const rule  = it.rule_id || 'N/A';
              const title = it.title || 'Issue';
              const expl  = it.explanation || '';
              const snippet = (it.problem_snippet || '').trim().slice(0, 1600);
              const fix     = (it.fix_suggestion || '').trim();
              const suggestion = fix
                ? ((COLLAPSE ? '<details><summary>Suggested change</summary>\n\n' : '') +
                   '```suggestion\n' + fix + '\n```\n' +
                   (COLLAPSE ? '\n</details>\n' : ''))
                : '';

              const body = (COMMENT_MARK + '\n' +
                '**[' + rule + '] ' + title + '**\n\n' +
                expl + '\n\n' +
                '**Проблемный код:**\n' +
                '[' + it.file + '#L' + anchor + '](' + fileUrl + ')  ・  [VS Code](' + vsUrl + ')\n\n' +
                '```dart\n' + snippet + '\n```\n\n' +
                suggestion).trim();

              draftComments.push({
                path: it.file,
                line: Number(anchor),
                side: 'RIGHT',
                body
              });
            }

            let reviewId = null;
            let batchOK = false;

            // Try batch review with line/side + commit_id
            const prHeadOk = !!prHeadSha;
            if (canInline && draftComments.length && prHeadOk) {
              try {
                const review = await github.rest.pulls.createReview({
                  owner, repo, pull_number: pr,
                  event: 'COMMENT',
                  commit_id: prHeadSha,
                  comments: draftComments
                });
                reviewId = review.data?.id || null;
                batchOK = !!reviewId;
              } catch (e) {
                core.warning('Batch review (line/side) failed: ' + (e?.message || e));
              }
            }

            // Fallback: pending review + per-comment + submit
            if (canInline && !batchOK && draftComments.length && prHeadOk) {
              try {
                const pending = await github.rest.pulls.createReview({
                  owner, repo, pull_number: pr,
                  event: 'PENDING',
                  commit_id: prHeadSha
                });
                reviewId = pending.data?.id || null;

                if (reviewId) {
                  for (const c of draftComments) {
                    await github.rest.pulls.createReviewComment({
                      owner, repo, pull_number: pr,
                      pull_request_review_id: reviewId,
                      path: c.path,
                      line: c.line,
                      side: c.side,
                      body: c.body,
                      commit_id: prHeadSha
                    }).catch(err => core.warning('add comment failed: ' + (err?.message || err)));
                  }

                  await github.rest.pulls.submitReview({
                    owner, repo, pull_number: pr,
                    review_id: reviewId,
                    event: 'COMMENT'
                  });
                  batchOK = true;
                }
              } catch (e) {
                core.warning('Fallback pending+submit failed: ' + (e?.message || e));
              }
            }

            // --- Checks output ---
            if (ENABLE_CHECKS) {
              try {
                const check = await github.rest.checks.create({
                  owner, repo, name: 'AI PR Review', head_sha: prHeadSha, status: 'in_progress'
                });
                const checkRunId = check.data.id;
                const annotations = [];
                for (const it of allIssues.slice(0, 200)) {
                  if (!it.file || !it.start_line || !it.end_line) continue;
                  annotations.push({
                    path: it.file,
                    start_line: Number(it.start_line),
                    end_line: Number(it.end_line),
                    annotation_level: 'warning',
                    message: `${it.rule_id || 'N/A'}: ${it.title || ''}\n\n${it.explanation || ''}`.trim()
                  });
                }
                const MAX_ANN = 50; let i = 0;
                if (!annotations.length) {
                  await github.rest.checks.update({
                    owner, repo, check_run_id: checkRunId,
                    output: { title: 'AI PR Review', summary: 'Нет замечаний по добавленным строкам.' },
                    status: 'completed', conclusion: 'success'
                  });
                } else {
                  while (i < annotations.length) {
                    const chunk = annotations.slice(i, i + MAX_ANN); i += MAX_ANN;
                    await github.rest.checks.update({
                      owner, repo, check_run_id: checkRunId,
                      output: { title: 'AI PR Review', summary: `Найдено замечаний: ${annotations.length}. См. inline-комментарии.`, annotations: chunk },
                      status: i >= annotations.length ? 'completed' : 'in_progress',
                      conclusion: i >= annotations.length ? 'neutral' : undefined
                    });
                  }
                }
              } catch (e) { core.warning('Checks failed: ' + (e?.message || e)); }
            }

            // --- Final message ---
            if (!allIssues.length) {
              await github.rest.issues.createComment({
                owner, repo, issue_number: pr,
                body: COMMENT_MARK + '\nНет замечаний по добавленным строкам.'
              });
            } else if (canInline && !batchOK) {
              await github.rest.issues.createComment({
                owner, repo, issue_number: pr,
                body: COMMENT_MARK + '\nСозданы замечания, но inline не удалось прикрепить даже через фолбэк. ' +
                      'Проверь, не уехали ли строки относительно HEAD и нет ли rename/двойных патчей.'
              });
            }